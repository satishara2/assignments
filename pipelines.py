# -*- coding: utf-8 -*-
"""Pipelines.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JGpX9-s4YkWZK6sICCrQsjGRKZjtpHOC
"""

# Import data -> transformations -> -> handle missing values -> outlier detection -> encoding -> split the data -> apply models -> deploy the models

import pandas as pd
import numpy as np

diamonds = pd.read_csv('https://raw.githubusercontent.com/Hemanthkaruturi/python_for_datascience/master/data/diamonds.csv')

diamonds.head()

# Step 1: delete unwanted columns
diamonds = diamonds.drop(columns='Unnamed: 0')

# Step 2: check missing values
diamonds.isnull().sum()

# step 3: check for outliers
# passing

#! pip install category_encoders

# step 4: encoding of the categoical variables
cat_cols = diamonds.select_dtypes('object').columns

from category_encoders import OneHotEncoder
ohe = OneHotEncoder(cols=cat_cols, use_cat_names=True)
diamonds_data = ohe.fit_transform(diamonds)

# step 5: Standardization or Normalization

ind_vars = diamonds_data.drop(columns='price')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
X = ss.fit_transform(ind_vars)

y = diamonds_data['price']

# step 6: split data to train and test sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25)

# step 7: Apply the model
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

rf_model = RandomForestRegressor()
rf_model.fit(X_train, y_train)
predictions = rf_model.predict(X_test)

print("RMSE: {}".format(np.sqrt(mean_squared_error(y_test, predictions))))

"""## Pipeline"""

# import data
# removed unwanted column (Column transformation)
# One hot encoding 
# Normalizing the data 
#### splitting data to train and test sets (train, test)
# applying the model

!pip install category_encoders

import pandas as pd
import numpy as np

diamonds = pd.read_csv('https://raw.githubusercontent.com/Hemanthkaruturi/python_for_datascience/master/data/diamonds.csv')

from sklearn.compose import ColumnTransformer

pre_processing = ColumnTransformer(
    transformers = [('drop column', 'drop', ['Unnamed: 0'])],
    remainder = 'passthrough'
)

from category_encoders import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline

cat_cols = diamonds.select_dtypes('object').columns
pipeline_model = Pipeline(steps=[
                                 ('Onehotencoding', OneHotEncoder(cols=cat_cols, use_cat_names=True)),
                                 ('Pre processing', pre_processing),
                                 ('Standardization', StandardScaler()),
                                 ('Random Forest', RandomForestRegressor())
])

train_x = diamonds.drop(columns='price')
train_y = diamonds['price']

train_x

pipeline_model.fit(train_x, train_y)

train_x

pipeline_model.predict(train_x)

diamonds['clarity'].value_counts()

diamonds.columns

diamonds.columns = [' Unnamed: 0', 'carat ', 'cut ', ' color', 'clarity', 'depth', 'table', 'price', 'x ', ' y', 'z']

strip_spaces = lambda x: x.strip()
list(map(strip_spaces, diamonds.columns))

diamonds['clarity'].value_counts()

create_other = lambda x: 'Other' if (x == 'IF') or (x == 'I1') else x
diamonds['clarity'].apply(create_other)

from sklearn.base import BaseEstimator

class Strip_spaces(BaseEstimator):
  def __init__(self):
    pass
  
  def fit(self, data, y=None):
    return self
  
  def transform(self, data, y=None):
    strip_spaces = lambda x: x.strip()
    data.columns = list(map(strip_spaces, data.columns))
    return data

class Create_other(BaseEstimator):
  def __init__(self):
    pass
  
  def fit(self, data, y=None):
    return self
  
  def transform(self, data, y=None):
    create_other = lambda x: 'Other' if (x == 'IF') or (x == 'I1') else x
    data['clarity'] = data['clarity'].apply(create_other)
    return data

from sklearn.compose import ColumnTransformer

pre_processing = ColumnTransformer(
    transformers = [('drop column', 'drop', ['Unnamed: 0'])],
    remainder = 'passthrough'
)

from category_encoders import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline

pipeline_model = Pipeline(steps=[
                                 ('Strip spaces', Strip_spaces()),
                                 ('Create other', Create_other()),
                                 ('Onehotencoding', OneHotEncoder(cols=cat_cols, use_cat_names=True)),
                                 ('Pre processing', pre_processing),
                                 ('Standardization', StandardScaler()),
                                 ('Random Forest', RandomForestRegressor())


])

cat_cols = ['cut', 'color', 'clarity']

#cat_cols = diamonds.select_dtypes('object').columns
train_x = diamonds.drop(columns='price')
train_y = diamonds['price']

train_x

pipeline_model.fit(train_x, train_y)

pipeline_model.predict(train_x)

